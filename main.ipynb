{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import dataloader\n",
    "import architecture\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '.'\n",
    "DATA_DIR = 'BRATS_2018'\n",
    "LABELED_DIR = 'MICCAI_BraTS_2018_Data_Training'\n",
    "UNLABELED_DIR = 'MICCAI_BraTS_2018_Data_Validation'\n",
    "LABELED_PATH = os.path.join(ROOT_DIR, DATA_DIR, LABELED_DIR)\n",
    "UNLABELED_PATH = os.path.join(ROOT_DIR, DATA_DIR, UNLABELED_DIR)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BRAIN_SLICES = 8\n",
    "NUM_CLASSES = 4\n",
    "X_DTYPE = np.float32\n",
    "Y_DTYPE = np.uint8\n",
    "MAX_VALUE = 32767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, sizes = dataloader.load_dataset_paths(LABELED_PATH, UNLABELED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_brains, val_brains, test_brains, unlabeled_brains = paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgg_train_size, lgg_train_size, hgg_val_size, lgg_val_size = sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgg_train_size, lgg_train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 49, 44, 66)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_brains), len(val_brains), len(test_brains), len(unlabeled_brains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_brains = train_brains + val_brains + test_brains + unlabeled_brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader.find_max_per_channel(all_brains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(dataloader.build_data_generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, dataloader.CHANNELS), dtype=X_DTYPE),\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, NUM_CLASSES), dtype=Y_DTYPE)\n",
    "), args=[train_brains, MAX_VALUE, BATCH_SIZE, BRAIN_SLICES, True, hgg_train_size, lgg_train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_generator(dataloader.build_data_generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, dataloader.CHANNELS), dtype=X_DTYPE),\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, NUM_CLASSES), dtype=Y_DTYPE)\n",
    "), args=[val_brains, MAX_VALUE, BATCH_SIZE, BRAIN_SLICES, True, hgg_val_size, lgg_val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.repeat().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = val_dataset.repeat().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32767 36 13 <class 'numpy.float32'> <class 'numpy.uint8'> True None None\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Must specify maxval for integer dtype tf.int32\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\Dell\\Documents\\Studia\\magisterka\\projekt\\dataloader.py\", line 166, in build_data_generator\n    yield generator.__getitem__(i)\n\n  File \"c:\\Users\\Dell\\Documents\\Studia\\magisterka\\projekt\\dataloader.py\", line 109, in __getitem__\n    brain_scan_index = tf.random.uniform(shape=(), maxval=self.hgg_size, dtype=tf.int32).numpy() if sample < self.sample_size//2 else tf.random.uniform(shape=(), minval=self.hgg_size, maxval=(self.hgg_size + self.lgg_size), dtype=tf.int32).numpy()\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 295, in random_uniform\n    raise ValueError(\"Must specify maxval for integer dtype %r\" % dtype)\n\nValueError: Must specify maxval for integer dtype tf.int32\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10008/3864974154.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0melo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    812\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[1;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    778\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3053\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3054\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3055\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3056\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3057\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6654\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6655\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6656\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Must specify maxval for integer dtype tf.int32\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\Dell\\Documents\\Studia\\magisterka\\projekt\\dataloader.py\", line 166, in build_data_generator\n    yield generator.__getitem__(i)\n\n  File \"c:\\Users\\Dell\\Documents\\Studia\\magisterka\\projekt\\dataloader.py\", line 109, in __getitem__\n    brain_scan_index = tf.random.uniform(shape=(), maxval=self.hgg_size, dtype=tf.int32).numpy() if sample < self.sample_size//2 else tf.random.uniform(shape=(), minval=self.hgg_size, maxval=(self.hgg_size + self.lgg_size), dtype=tf.int32).numpy()\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 295, in random_uniform\n    raise ValueError(\"Must specify maxval for integer dtype %r\" % dtype)\n\nValueError: Must specify maxval for integer dtype tf.int32\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "for elem in val_dataset.take(1):\n",
    "    elo = elem[0][0, :, :, 0]\n",
    "    print(elo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = architecture.build_model((dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, dataloader.CHANNELS), NUM_CLASSES, 'relu', 'he_normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 96, 112, 4)]         0         []                            \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)  (None, 96, 112, 16)          2480      ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " inception_module_12 (Incep  (None, 48, 56, 16)           824       ['sequential_15[0][0]']       \n",
      " tionModule)                                                                                      \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)  (None, 48, 56, 32)           38176     ['inception_module_12[0][0]'] \n",
      "                                                                                                  \n",
      " inception_module_13 (Incep  (None, 24, 28, 32)           3248      ['sequential_16[0][0]']       \n",
      " tionModule)                                                                                      \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)  (None, 24, 28, 64)           300096    ['inception_module_13[0][0]'] \n",
      "                                                                                                  \n",
      " inception_module_14 (Incep  (None, 12, 14, 64)           12896     ['sequential_17[0][0]']       \n",
      " tionModule)                                                                                      \n",
      "                                                                                                  \n",
      " sequential_18 (Sequential)  (None, 12, 14, 128)          2379904   ['inception_module_14[0][0]'] \n",
      "                                                                                                  \n",
      " inception_module_15 (Incep  (None, 6, 7, 128)            51392     ['sequential_18[0][0]']       \n",
      " tionModule)                                                                                      \n",
      "                                                                                                  \n",
      " sequential_19 (Sequential)  (None, 6, 7, 256)            1895654   ['inception_module_15[0][0]'] \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2D  (None, 12, 14, 128)          131200    ['sequential_19[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 12, 14, 256)          0         ['conv2d_transpose_5[0][0]',  \n",
      " )                                                                   'sequential_18[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_20 (Sequential)  (None, 12, 14, 128)          346432    ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2D  (None, 24, 28, 64)           32832     ['sequential_20[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 24, 28, 128)          0         ['conv2d_transpose_6[0][0]',  \n",
      " )                                                                   'sequential_17[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)  (None, 24, 28, 64)           86688     ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2D  (None, 48, 56, 32)           8224      ['sequential_21[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 48, 56, 64)           0         ['conv2d_transpose_7[0][0]',  \n",
      " )                                                                   'sequential_16[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_22 (Sequential)  (None, 48, 56, 32)           21712     ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2D  (None, 96, 112, 16)          2064      ['sequential_22[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 96, 112, 32)          0         ['conv2d_transpose_8[0][0]',  \n",
      " )                                                                   'sequential_15[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_23 (Sequential)  (None, 96, 112, 16)          5448      ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 96, 112, 5)           85        ['sequential_23[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22380245 (85.37 MB)\n",
      "Trainable params: 22380245 (85.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(), metrics=['accuracy', \n",
    "                                                                                               tf.keras.metrics.OneHotMeanIoU(num_classes=NUM_CLASSES),\n",
    "                                                                                               tf.keras.metrics.OneHotIoU(num_classes=NUM_CLASSES, target_class_ids=[0]),\n",
    "                                                                                               tf.keras.metrics.OneHotIoU(num_classes=NUM_CLASSES, target_class_ids=[1]),\n",
    "                                                                                               tf.keras.metrics.OneHotIoU(num_classes=NUM_CLASSES, target_class_ids=[2]),\n",
    "                                                                                               tf.keras.metrics.OneHotIoU(num_classes=NUM_CLASSES, target_class_ids=[3]),\n",
    "                                                                                               metrics.weighted_f1,\n",
    "                                                                                               tf.keras.metrics.Precision(class_id=0),\n",
    "                                                                                               tf.keras.metrics.Precision(class_id=1),\n",
    "                                                                                               tf.keras.metrics.Precision(class_id=2),\n",
    "                                                                                               tf.keras.metrics.Precision(class_id=3),\n",
    "                                                                                               tf.keras.metrics.Recall(class_id=0),\n",
    "                                                                                               tf.keras.metrics.Recall(class_id=1),\n",
    "                                                                                               tf.keras.metrics.Recall(class_id=2),\n",
    "                                                                                               tf.keras.metrics.Recall(class_id=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.path.join(ROOT_DIR, 'checkpoints', 'model-{epoch:02d}-{val_one_hot_mean_io_u:.3f}')\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_one_hot_mean_io_u',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "csv_logger_callback = tf.keras.callbacks.CSVLogger('brainTumor.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 103s 31s/step - loss: 1.3730 - accuracy: 0.2133 - one_hot_mean_io_u: 0.0545 - one_hot_io_u: 0.2142 - one_hot_io_u_1: 0.0000e+00 - one_hot_io_u_2: 0.0020 - one_hot_io_u_3: 0.0018 - weighted_f1: 0.3980 - precision: 0.0000e+00 - precision_1: 0.0000e+00 - precision_2: 0.0000e+00 - precision_3: 0.0000e+00 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.2065 - val_accuracy: 0.2397 - val_one_hot_mean_io_u: 0.0607 - val_one_hot_io_u: 0.2408 - val_one_hot_io_u_1: 0.0000e+00 - val_one_hot_io_u_2: 0.0018 - val_one_hot_io_u_3: 0.0000e+00 - val_weighted_f1: 0.4565 - val_precision: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00 - val_recall_3: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1, steps_per_epoch=3, validation_data=val_dataset, validation_steps=3, callbacks=[model_checkpoint_callback,\n",
    "                                                                                                                            early_stop_callback,\n",
    "                                                                                                                            csv_logger_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3730391263961792],\n",
       " 'accuracy': [0.21328862011432648],\n",
       " 'one_hot_mean_io_u': [0.05450255796313286],\n",
       " 'one_hot_io_u': [0.2141568660736084],\n",
       " 'one_hot_io_u_1': [0.0],\n",
       " 'one_hot_io_u_2': [0.002016012789681554],\n",
       " 'one_hot_io_u_3': [0.0018373513594269753],\n",
       " 'weighted_f1': [0.3980276584625244],\n",
       " 'precision': [0.0],\n",
       " 'precision_1': [0.0],\n",
       " 'precision_2': [0.0],\n",
       " 'precision_3': [0.0],\n",
       " 'recall': [0.0],\n",
       " 'recall_1': [0.0],\n",
       " 'recall_2': [0.0],\n",
       " 'recall_3': [0.0],\n",
       " 'val_loss': [1.2064648866653442],\n",
       " 'val_accuracy': [0.23973019421100616],\n",
       " 'val_one_hot_mean_io_u': [0.06065306067466736],\n",
       " 'val_one_hot_io_u': [0.2408376783132553],\n",
       " 'val_one_hot_io_u_1': [0.0],\n",
       " 'val_one_hot_io_u_2': [0.001774563454091549],\n",
       " 'val_one_hot_io_u_3': [0.0],\n",
       " 'val_weighted_f1': [0.4565224349498749],\n",
       " 'val_precision': [0.0],\n",
       " 'val_precision_1': [0.0],\n",
       " 'val_precision_2': [0.0],\n",
       " 'val_precision_3': [0.0],\n",
       " 'val_recall': [0.0],\n",
       " 'val_recall_1': [0.0],\n",
       " 'val_recall_2': [0.0],\n",
       " 'val_recall_3': [0.0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "768/768 [==============================] - 3951s 5s/step - loss: 0.1080 - accuracy: 0.9780 - val_loss: 0.1126 - val_accuracy: 0.9794\n",
      "Epoch 2/2\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1536 batches). You may need to use the repeat() function when building your dataset.\n",
      "768/768 [==============================] - 169s 220ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.1126 - val_accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1, steps_per_epoch=len(train_brains) * (dataloader.BRAIN_FRAMES//BATCH_SIZE), validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 195s 854ms/step - loss: 0.0924 - accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09240186959505081, 0.9781610369682312]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
