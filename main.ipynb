{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import dataloader\n",
    "import architecture\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '.'\n",
    "DATA_DIR = 'BRATS_2018'\n",
    "LABELED_DIR = 'MICCAI_BraTS_2018_Data_Training'\n",
    "UNLABELED_DIR = 'MICCAI_BraTS_2018_Data_Validation'\n",
    "LABELED_PATH = os.path.join(ROOT_DIR, DATA_DIR, LABELED_DIR)\n",
    "UNLABELED_PATH = os.path.join(ROOT_DIR, DATA_DIR, UNLABELED_DIR)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BRAIN_SLICES = 8\n",
    "NUM_CLASSES = 4\n",
    "X_DTYPE = np.float32\n",
    "Y_DTYPE = np.uint8\n",
    "MAX_VALUE = 32767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, sizes = dataloader.load_dataset_paths(LABELED_PATH, UNLABELED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_brains, val_brains, test_brains, unlabeled_brains = paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgg_train_size, lgg_train_size, hgg_val_size, lgg_val_size = sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgg_train_size, lgg_train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 49, 44, 66)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_brains), len(val_brains), len(test_brains), len(unlabeled_brains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_brains = train_brains + val_brains + test_brains + unlabeled_brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 32767.0, 't1ce': 32767.0, 't2': 32767.0, 'flair': 32767.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloader.find_max_per_channel(all_brains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(dataloader.build_data_generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, dataloader.CHANNELS), dtype=X_DTYPE),\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, NUM_CLASSES), dtype=Y_DTYPE)\n",
    "), args=[train_brains, MAX_VALUE, BATCH_SIZE, BRAIN_SLICES, X_DTYPE, Y_DTYPE, True, hgg_train_size, lgg_train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_generator(dataloader.build_data_generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, dataloader.CHANNELS), dtype=X_DTYPE),\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, NUM_CLASSES), dtype=Y_DTYPE)\n",
    "), args=[val_brains, MAX_VALUE, BATCH_SIZE, BRAIN_SLICES, X_DTYPE, Y_DTYPE, True, hgg_val_size, lgg_val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.repeat().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = val_dataset.repeat().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for elem in val_dataset.take(1):\n",
    "#     plt.imshow(elem[0][0, :, :, 0])\n",
    "#     elo = elem[0][0, :, :, 0]\n",
    "#     print(elo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = architecture.build_model((dataloader.IMAGE_SIZE, dataloader.IMAGE_SIZE, dataloader.CHANNELS), NUM_CLASSES, 'relu', 'he_normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 96, 112, 4)]         0         []                            \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)  (None, 96, 112, 16)          2480      ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " inception_module_12 (Incep  (None, 48, 56, 16)           824       ['sequential_15[0][0]']       \n",
      " tionModule)                                                                                      \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)  (None, 48, 56, 32)           38176     ['inception_module_12[0][0]'] \n",
      "                                                                                                  \n",
      " inception_module_13 (Incep  (None, 24, 28, 32)           3248      ['sequential_16[0][0]']       \n",
      " tionModule)                                                                                      \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)  (None, 24, 28, 64)           300096    ['inception_module_13[0][0]'] \n",
      "                                                                                                  \n",
      " inception_module_14 (Incep  (None, 12, 14, 64)           12896     ['sequential_17[0][0]']       \n",
      " tionModule)                                                                                      \n",
      "                                                                                                  \n",
      " sequential_18 (Sequential)  (None, 12, 14, 128)          2379904   ['inception_module_14[0][0]'] \n",
      "                                                                                                  \n",
      " inception_module_15 (Incep  (None, 6, 7, 128)            51392     ['sequential_18[0][0]']       \n",
      " tionModule)                                                                                      \n",
      "                                                                                                  \n",
      " sequential_19 (Sequential)  (None, 6, 7, 256)            1895654   ['inception_module_15[0][0]'] \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2D  (None, 12, 14, 128)          131200    ['sequential_19[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 12, 14, 256)          0         ['conv2d_transpose_5[0][0]',  \n",
      " )                                                                   'sequential_18[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_20 (Sequential)  (None, 12, 14, 128)          346432    ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2D  (None, 24, 28, 64)           32832     ['sequential_20[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 24, 28, 128)          0         ['conv2d_transpose_6[0][0]',  \n",
      " )                                                                   'sequential_17[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)  (None, 24, 28, 64)           86688     ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2D  (None, 48, 56, 32)           8224      ['sequential_21[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 48, 56, 64)           0         ['conv2d_transpose_7[0][0]',  \n",
      " )                                                                   'sequential_16[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_22 (Sequential)  (None, 48, 56, 32)           21712     ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2D  (None, 96, 112, 16)          2064      ['sequential_22[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 96, 112, 32)          0         ['conv2d_transpose_8[0][0]',  \n",
      " )                                                                   'sequential_15[0][0]']       \n",
      "                                                                                                  \n",
      " sequential_23 (Sequential)  (None, 96, 112, 16)          5448      ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 96, 112, 5)           85        ['sequential_23[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22380245 (85.37 MB)\n",
      "Trainable params: 22380245 (85.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(), metrics=['accuracy', \n",
    "                                                                                               tf.keras.metrics.OneHotMeanIoU(num_classes=NUM_CLASSES),\n",
    "                                                                                               tf.keras.metrics.OneHotIoU(num_classes=NUM_CLASSES, target_class_ids=[0]),\n",
    "                                                                                               tf.keras.metrics.OneHotIoU(num_classes=NUM_CLASSES, target_class_ids=[1]),\n",
    "                                                                                               tf.keras.metrics.OneHotIoU(num_classes=NUM_CLASSES, target_class_ids=[2]),\n",
    "                                                                                               tf.keras.metrics.OneHotIoU(num_classes=NUM_CLASSES, target_class_ids=[3]),\n",
    "                                                                                               metrics.weighted_f1,\n",
    "                                                                                               tf.keras.metrics.Precision(class_id=0),\n",
    "                                                                                               tf.keras.metrics.Precision(class_id=1),\n",
    "                                                                                               tf.keras.metrics.Precision(class_id=2),\n",
    "                                                                                               tf.keras.metrics.Precision(class_id=3),\n",
    "                                                                                               tf.keras.metrics.Recall(class_id=0),\n",
    "                                                                                               tf.keras.metrics.Recall(class_id=1),\n",
    "                                                                                               tf.keras.metrics.Recall(class_id=2),\n",
    "                                                                                               tf.keras.metrics.Recall(class_id=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.path.join(ROOT_DIR, 'checkpoints', 'model-{epoch:02d}-{val_one_hot_mean_io_u:.3f}')\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_one_hot_mean_io_u',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "csv_logger_callback = tf.keras.callbacks.CSVLogger('brainTumor.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 103s 31s/step - loss: 1.3730 - accuracy: 0.2133 - one_hot_mean_io_u: 0.0545 - one_hot_io_u: 0.2142 - one_hot_io_u_1: 0.0000e+00 - one_hot_io_u_2: 0.0020 - one_hot_io_u_3: 0.0018 - weighted_f1: 0.3980 - precision: 0.0000e+00 - precision_1: 0.0000e+00 - precision_2: 0.0000e+00 - precision_3: 0.0000e+00 - recall: 0.0000e+00 - recall_1: 0.0000e+00 - recall_2: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.2065 - val_accuracy: 0.2397 - val_one_hot_mean_io_u: 0.0607 - val_one_hot_io_u: 0.2408 - val_one_hot_io_u_1: 0.0000e+00 - val_one_hot_io_u_2: 0.0018 - val_one_hot_io_u_3: 0.0000e+00 - val_weighted_f1: 0.4565 - val_precision: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_precision_3: 0.0000e+00 - val_recall: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_recall_2: 0.0000e+00 - val_recall_3: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1, steps_per_epoch=3, validation_data=val_dataset, validation_steps=3, callbacks=[model_checkpoint_callback,\n",
    "                                                                                                                            early_stop_callback,\n",
    "                                                                                                                            csv_logger_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3730391263961792],\n",
       " 'accuracy': [0.21328862011432648],\n",
       " 'one_hot_mean_io_u': [0.05450255796313286],\n",
       " 'one_hot_io_u': [0.2141568660736084],\n",
       " 'one_hot_io_u_1': [0.0],\n",
       " 'one_hot_io_u_2': [0.002016012789681554],\n",
       " 'one_hot_io_u_3': [0.0018373513594269753],\n",
       " 'weighted_f1': [0.3980276584625244],\n",
       " 'precision': [0.0],\n",
       " 'precision_1': [0.0],\n",
       " 'precision_2': [0.0],\n",
       " 'precision_3': [0.0],\n",
       " 'recall': [0.0],\n",
       " 'recall_1': [0.0],\n",
       " 'recall_2': [0.0],\n",
       " 'recall_3': [0.0],\n",
       " 'val_loss': [1.2064648866653442],\n",
       " 'val_accuracy': [0.23973019421100616],\n",
       " 'val_one_hot_mean_io_u': [0.06065306067466736],\n",
       " 'val_one_hot_io_u': [0.2408376783132553],\n",
       " 'val_one_hot_io_u_1': [0.0],\n",
       " 'val_one_hot_io_u_2': [0.001774563454091549],\n",
       " 'val_one_hot_io_u_3': [0.0],\n",
       " 'val_weighted_f1': [0.4565224349498749],\n",
       " 'val_precision': [0.0],\n",
       " 'val_precision_1': [0.0],\n",
       " 'val_precision_2': [0.0],\n",
       " 'val_precision_3': [0.0],\n",
       " 'val_recall': [0.0],\n",
       " 'val_recall_1': [0.0],\n",
       " 'val_recall_2': [0.0],\n",
       " 'val_recall_3': [0.0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "768/768 [==============================] - 3951s 5s/step - loss: 0.1080 - accuracy: 0.9780 - val_loss: 0.1126 - val_accuracy: 0.9794\n",
      "Epoch 2/2\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1536 batches). You may need to use the repeat() function when building your dataset.\n",
      "768/768 [==============================] - 169s 220ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.1126 - val_accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1, steps_per_epoch=len(train_brains) * (dataloader.BRAIN_FRAMES//BATCH_SIZE), validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 195s 854ms/step - loss: 0.0924 - accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09240186959505081, 0.9781610369682312]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
